<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Tech Bytes</title>
<link>https://nishantbharali.github.io/Blog/blog.html</link>
<atom:link href="https://nishantbharali.github.io/Blog/blog.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://nishantbharali.github.io/Blog/images/handsOnGif.gif</url>
<title>Tech Bytes</title>
<link>https://nishantbharali.github.io/Blog/blog.html</link>
</image>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Fri, 24 Nov 2023 05:00:00 GMT</lastBuildDate>
<item>
  <title>Anomaly/Outlier Detection in a Financial Dataset</title>
  <dc:creator>Nishant Bharali</dc:creator>
  <link>https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index.html</link>
  <description><![CDATA[ 



<section id="anomalyoutlier-detection-in-a-financial-dataset" class="level2">
<h2 class="anchored" data-anchor-id="anomalyoutlier-detection-in-a-financial-dataset">Anomaly/Outlier Detection in a Financial Dataset</h2>
<p><strong>Detecting anomalies in financial data involves using specialized algorithms to identify irregularities, enhancing risk management and fraud prevention</strong></p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In the modern world of finance, data plays a pivotal role in decision-making processes. Financial datasets often contain critical information about customers, transactions, and more. One crucial aspect of financial data analysis is the detection of anomalies or outliers. Anomalies are data points that significantly deviate from the norm or expected behavior. Detecting these anomalies is essential for fraud detection, risk management, and maintaining data integrity.</p>
<p>This report explores the application of anomaly/outlier detection techniques to a financial dataset. The dataset under consideration contains information such as Age, Income, Transaction Amount, Transaction Type, and Location. We aim to identify unusual patterns or data points within this dataset that may require further investigation.</p>
<p><strong>Advanced Analysis</strong></p>
<p>I will now conduct an advanced analysis of this dataset, focusing on the following aspects:</p>
<p>Data Exploration: Understanding the basic statistics of the dataset. Visualization: Plotting the data to observe any unusual patterns. Anomaly Detection Techniques: Implementing various methods to detect outliers, such as statistical methods, clustering-based methods, and machine learning models. For this analysis, I will be using Python libraries like Pandas, NumPy, Matplotlib, Seaborn, and Scikit-Learn. Let’s start with the data exploration and visualization.</p>
<p><strong>Analysis Overview</strong></p>
<p><strong>Data Exploration</strong></p>
<p>The descriptive statistics of the dataset provide a basic understanding of its features:</p>
<p>A. Age: Ranges from 18 to 69, with an average of around 43 years. B. Income: The average income is approximately $51,518, with a wide range from around $988 to $181,196, suggesting significant variance. C. Transaction Amount: On average, transactions are around $200, but there are values as high as $1,999, which might indicate potential outliers.</p>
<p><strong>Visualization Insights</strong></p>
<p>A. Histograms: These show the distribution of numerical features. While age appears fairly uniformly distributed, income and transaction amounts show right-skewed distributions. B. Boxplots: The boxplots highlight potential outliers, especially in the income and transaction amount data. PCA Scatter Plot: After applying PCA for dimensionality reduction, we get a 2D visualization of the scaled numerical data. This plot can help us identify clusters and potential outliers visually.</p>
<p><strong>Next Steps for Anomaly Detection</strong></p>
<p>Based on these visualizations and statistics, the next step is to apply anomaly detection techniques. I will use the Isolation Forest algorithm, a popular method for outlier detection, especially effective with high-dimensional datasets. This method isolates anomalies instead of profiling normal data points. Anomalies are few and different, hence easier to isolate.</p>
</section>
<section id="data-exploration-and-analysis" class="level2">
<h2 class="anchored" data-anchor-id="data-exploration-and-analysis">Data Exploration and Analysis</h2>
<p>I applied the Isolation Forest algorithm to our scaled numerical data and identify the anomalies. Let’s proceed with this analysis.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> IsolationForest</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.decomposition <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PCA</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Loading the dataset</span></span>
<span id="cb1-9">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'anomaly_detection_dataset.csv'</span>)</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Data Exploration: Descriptive statistics</span></span>
<span id="cb1-12">descriptive_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.describe()</span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display basic statistics</span></span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualization</span></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Histograms for numerical data</span></span>
<span id="cb1-17">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(nrows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, ncols<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb1-18">df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Transaction Amount'</span>]].hist(bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'skyblue'</span>)</span>
<span id="cb1-19">plt.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Histograms of Numerical Features'</span>)</span>
<span id="cb1-20"></span>
<span id="cb1-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Boxplot for numerical data to check for outliers</span></span>
<span id="cb1-22">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(nrows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, ncols<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb1-23">sns.boxplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Transaction Amount'</span>]], ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb1-24">sns.boxplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>]], ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb1-25">sns.boxplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Transaction Amount'</span>]], ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb1-26">plt.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxplots of Numerical Features'</span>)</span>
<span id="cb1-27"></span>
<span id="cb1-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Preparing data for anomaly detection</span></span>
<span id="cb1-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Standardizing the numerical data</span></span>
<span id="cb1-30">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb1-31">scaled_numerical_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Transaction Amount'</span>]])</span>
<span id="cb1-32"></span>
<span id="cb1-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Applying PCA for dimensionality reduction (2D visualization)</span></span>
<span id="cb1-34">pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PCA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-35">pca_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca.fit_transform(scaled_numerical_data)</span>
<span id="cb1-36">pca_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pca_results, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PC1'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PC2'</span>])</span>
<span id="cb1-37"></span>
<span id="cb1-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Scatter plot of PCA results</span></span>
<span id="cb1-39">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb1-40">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PC1'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PC2'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pca_df)</span>
<span id="cb1-41">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PCA of Scaled Numerical Data'</span>)</span>
<span id="cb1-42"></span>
<span id="cb1-43">plt.show()</span>
<span id="cb1-44"></span>
<span id="cb1-45">descriptive_stats, pca_df.head()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-2-output-1.png" width="1385" height="459"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-2-output-2.png" width="1418" height="459"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-2-output-3.png" width="810" height="523"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>(               Age         Income  Transaction Amount
 count  1000.000000    1000.000000         1000.000000
 mean     43.267000   51518.424999          200.855857
 std      15.242311   18506.474035          197.923861
 min      18.000000     988.660890            0.381117
 25%      30.000000   39745.904804           79.905356
 50%      43.000000   50483.467494          162.361081
 75%      56.000000   60698.045016          264.145550
 max      69.000000  181196.443031         1999.137390,
         PC1       PC2
 0 -0.301194 -1.080589
 1 -0.282737 -0.824039
 2 -0.474600  2.067434
 3  0.344241  0.305833
 4 -0.009123  0.894454)</code></pre>
</div>
</div>
<p><strong>Data Visualization</strong></p>
<p>Next, we visualize the data to identify any obvious outliers or patterns.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Histograms for numerical features</span></span>
<span id="cb3-5">df.hist(bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb3-6">plt.show()</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Box plots for numerical features to identify outliers</span></span>
<span id="cb3-9">df.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>, subplots<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, layout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>), figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb3-10">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-3-output-1.png" width="1170" height="505"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-3-output-2.png" width="1161" height="310"></p>
</div>
</div>
</section>
<section id="analysis-results-anomaly-detection-with-isolation-forest" class="level2">
<h2 class="anchored" data-anchor-id="analysis-results-anomaly-detection-with-isolation-forest">Analysis Results: Anomaly Detection with Isolation Forest</h2>
<p><strong>Anomaly Detection</strong></p>
<p>The Isolation Forest algorithm was applied to the scaled numerical data, and it identified 50 anomalies in our dataset. This is consistent with the initial contamination rate set to 5% of the data.</p>
<p><strong>Visualization of Detected Anomalies</strong></p>
<p>The scatter plot based on the PCA results with anomalies highlighted shows:</p>
<p>A. Normal data points in blue. B. Anomalies marked in red.</p>
<p>These anomalies represent unusual patterns in terms of age, income, and transaction amounts, as identified by the Isolation Forest algorithm.</p>
<p><strong>Interpretation</strong></p>
<p>The visualization clearly shows that the anomalies are distinct from the bulk of the data, signifying their outlier status. These could represent unusual financial transactions or demographic anomalies that would be of interest in real-world scenarios like fraud detection or targeted marketing.</p>
</section>
<section id="anomaly-detection-using-isolation-forest" class="level2">
<h2 class="anchored" data-anchor-id="anomaly-detection-using-isolation-forest">Anomaly Detection Using Isolation Forest</h2>
<p>We apply the Isolation Forest algorithm to detect anomalies in the dataset. This method is effective for high-dimensional datasets and does not require prior knowledge of the number of anomalies.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> IsolationForest</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Standardizing the data</span></span>
<span id="cb4-5">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb4-6">scaled_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(df.select_dtypes(include<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'float64'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'int64'</span>]))</span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Applying Isolation Forest</span></span>
<span id="cb4-9">iso_forest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> IsolationForest(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, contamination<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auto'</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb4-10">predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iso_forest.fit_predict(scaled_data)</span>
<span id="cb4-11"></span>
<span id="cb4-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add a column for anomaly (1 for normal, -1 for anomaly)</span></span>
<span id="cb4-13">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'anomaly'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predictions</span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Count the number of anomalies</span></span>
<span id="cb4-16">anomaly_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'anomaly'</span>].value_counts()</span>
<span id="cb4-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(anomaly_count)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>anomaly
 1    835
-1    165
Name: count, dtype: int64</code></pre>
</div>
</div>
<p><strong>Visualizing the Anomalies</strong></p>
<p>We can visualize the anomalies in the context of two principal components.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.decomposition <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PCA</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PCA for dimensionality reduction for visualization</span></span>
<span id="cb6-4">pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PCA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb6-5">pca_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca.fit_transform(scaled_data)</span>
<span id="cb6-6"></span>
<span id="cb6-7">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca1'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca_result[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb6-8">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca2'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca_result[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb6-9"></span>
<span id="cb6-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Scatter plot of the PCA results colored by anomaly</span></span>
<span id="cb6-11">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca1'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca2'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'anomaly'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>})</span>
<span id="cb6-12">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Anomalies in the PCA Plane'</span>)</span>
<span id="cb6-13">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-5-output-1.png" width="587" height="449"></p>
</div>
</div>
</section>
<section id="k-means-clustering-for-anomaly-detection" class="level2">
<h2 class="anchored" data-anchor-id="k-means-clustering-for-anomaly-detection">K-Means Clustering for Anomaly Detection</h2>
<p>K-Means can be used for anomaly detection by identifying small clusters as anomalies.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KMeans</span>
<span id="cb7-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># K-Means Clustering with explicit n_init parameter</span></span>
<span id="cb7-5">kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, n_init<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).fit(scaled_data)</span>
<span id="cb7-6">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cluster'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.labels_</span>
<span id="cb7-7"></span>
<span id="cb7-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Detecting outliers as the points farthest from the centroids</span></span>
<span id="cb7-9">distances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.transform(scaled_data)</span>
<span id="cb7-10">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'distance_to_centroid'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(distances, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-11">outlier_threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.percentile(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'distance_to_centroid'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">95</span>)</span>
<span id="cb7-12">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'outlier'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'distance_to_centroid'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> outlier_threshold</span></code></pre></div>
</div>
<p><strong>K-Means Clustering Visualization</strong></p>
<p>After running the K-Means algorithm, we can plot the data points and color them by their cluster. Points classified as outliers will be highlighted.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># K-Means Clustering Plot</span></span>
<span id="cb8-4">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb8-5">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca1'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca2'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cluster'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Set1'</span>)</span>
<span id="cb8-6">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'outlier'</span>]][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca1'</span>], y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'outlier'</span>]][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca2'</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Outlier'</span>)</span>
<span id="cb8-7">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K-Means Clustering'</span>)</span>
<span id="cb8-8">plt.legend()</span>
<span id="cb8-9">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-7-output-1.png" width="810" height="523"></p>
</div>
</div>
</section>
<section id="dbscan-for-anomaly-detection" class="level2">
<h2 class="anchored" data-anchor-id="dbscan-for-anomaly-detection">DBSCAN for Anomaly Detection</h2>
<p>DBSCAN is effective in identifying regions of high density and isolating outliers as points in low-density areas.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DBSCAN</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># DBSCAN Clustering</span></span>
<span id="cb9-4">dbscan <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DBSCAN(eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, min_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>).fit(scaled_data)</span>
<span id="cb9-5">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dbscan_labels'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dbscan.labels_</span>
<span id="cb9-6"></span>
<span id="cb9-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Anomalies are points with label -1</span></span>
<span id="cb9-8">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dbscan_outlier'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dbscan_labels'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
</div>
<p><strong>DBSCAN Visualization</strong></p>
<p>For DBSCAN, we will plot the data points and color them based on their cluster, highlighting the anomalies.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># DBSCAN Plot</span></span>
<span id="cb10-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb10-3">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca1'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca2'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dbscan_labels'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Set2'</span>)</span>
<span id="cb10-4">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dbscan_outlier'</span>]][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca1'</span>], y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dbscan_outlier'</span>]][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca2'</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Outlier'</span>)</span>
<span id="cb10-5">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'DBSCAN Clustering'</span>)</span>
<span id="cb10-6">plt.legend()</span>
<span id="cb10-7">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-9-output-1.png" width="810" height="523"></p>
</div>
</div>
</section>
<section id="local-outlier-factor-lof" class="level2">
<h2 class="anchored" data-anchor-id="local-outlier-factor-lof">Local Outlier Factor (LOF)</h2>
<p>LOF computes a score reflecting the degree of abnormality of the data, considering local density.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.neighbors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LocalOutlierFactor</span>
<span id="cb11-2"></span>
<span id="cb11-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LOF for anomaly detection</span></span>
<span id="cb11-4">lof <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LocalOutlierFactor(n_neighbors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, contamination<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>)</span>
<span id="cb11-5">lof_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lof.fit_predict(scaled_data)</span>
<span id="cb11-6"></span>
<span id="cb11-7">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lof_outlier'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lof_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
</div>
<p><strong>LOF Visualization</strong></p>
<p>Local Outlier Factor results can be visualized by highlighting the points that are identified as outliers.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LOF Plot</span></span>
<span id="cb12-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb12-3">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca1'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca2'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lof_outlier'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df)</span>
<span id="cb12-4">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Local Outlier Factor'</span>)</span>
<span id="cb12-5">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-11-output-1.png" width="810" height="523"></p>
</div>
</div>
<p><strong>T-SNE for Visualization of High-Dimensional Data</strong></p>
<p>T-SNE is effective for visualizing high-dimensional data and its anomalies in a lower-dimensional space.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.manifold <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TSNE</span>
<span id="cb13-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb13-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make sure to replace 'scaled_data' with your actual scaled data variable name</span></span>
<span id="cb13-6">tsne <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TSNE(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb13-7">tsne_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tsne.fit_transform(scaled_data)</span>
<span id="cb13-8"></span>
<span id="cb13-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding T-SNE results to your DataFrame</span></span>
<span id="cb13-10">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tsne1'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tsne_results[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb13-11">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tsne2'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tsne_results[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb13-12"></span>
<span id="cb13-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use 'dbscan_labels' or another column of your choice for coloring the points</span></span>
<span id="cb13-14">column_for_coloring <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dbscan_labels'</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Replace with your chosen column</span></span>
<span id="cb13-15"></span>
<span id="cb13-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># T-SNE Plot</span></span>
<span id="cb13-17">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb13-18">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tsne1'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tsne2'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>column_for_coloring, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Set2'</span>, legend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"full"</span>)</span>
<span id="cb13-19">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'T-SNE Visualization'</span>)</span>
<span id="cb13-20">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-12-output-1.png" width="819" height="523"></p>
</div>
</div>
<p>T-SNE results can be plotted to show how the data is distributed in the reduced-dimensional space, highlighting the anomalies detected.</p>
<p>These techniques represent a deeper dive into anomaly detection, leveraging different approaches from clustering, neural networks, and neighborhood-based methods. Each method has its strengths and can be combined or compared for a comprehensive anomaly detection strategy.</p>
</section>
<section id="final-check-for-anomaly-detection" class="level2">
<h2 class="anchored" data-anchor-id="final-check-for-anomaly-detection">Final check for Anomaly detection</h2>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Applying Isolation Forest for anomaly detection</span></span>
<span id="cb14-2">iso_forest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> IsolationForest(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, contamination<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb14-3">anomalies <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iso_forest.fit_predict(scaled_numerical_data)</span>
<span id="cb14-4"></span>
<span id="cb14-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding the anomaly predictions to the PCA DataFrame</span></span>
<span id="cb14-6">pca_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Anomaly'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> anomalies</span>
<span id="cb14-7"></span>
<span id="cb14-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualizing the identified anomalies on the PCA plot</span></span>
<span id="cb14-9">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb14-10">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PC1'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PC2'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Anomaly'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pca_df, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>})</span>
<span id="cb14-11">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PCA of Scaled Numerical Data with Anomalies Highlighted'</span>)</span>
<span id="cb14-12">plt.legend(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Anomaly'</span>, loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper right'</span>, labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Normal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Anomaly'</span>])</span>
<span id="cb14-13"></span>
<span id="cb14-14">plt.show()</span>
<span id="cb14-15"></span>
<span id="cb14-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Counting the number of detected anomalies</span></span>
<span id="cb14-17">num_anomalies_detected <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (anomalies <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb14-18"></span>
<span id="cb14-19">num_anomalies_detected, pca_df.head()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index_files/figure-html/cell-13-output-1.png" width="810" height="523"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>(50,
         PC1       PC2  Anomaly
 0 -0.301194 -1.080589        1
 1 -0.282737 -0.824039        1
 2 -0.474600  2.067434        1
 3  0.344241  0.305833        1
 4 -0.009123  0.894454        1)</code></pre>
</div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In conclusion, the analysis of anomalies and outliers in financial datasets is of paramount importance for safeguarding financial systems and ensuring data quality. In this report, we delved into the application of various techniques to detect anomalies in a financial dataset containing Age, Income, Transaction Amount, Transaction Type, and Location. The results of this analysis can guide decision-makers in identifying potential issues, such as fraudulent transactions or data entry errors.</p>
<p>By leveraging advanced analytics and machine learning algorithms, financial institutions can proactively mitigate risks, enhance customer trust, and streamline their operations. The continuous monitoring and refinement of anomaly detection methods are critical in the ever-evolving landscape of finance.</p>
<p>As financial data continues to grow in complexity and volume, the ability to detect anomalies accurately becomes increasingly crucial. It is essential for organizations to stay vigilant and adapt their anomaly detection strategies to stay ahead of emerging threats and challenges in the financial sector.</p>
<script>
const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
</script>
<style>
div#quarto-sidebar-glass { display: none !important; }
ul.navbar-nav.navbar-nav-scroll { -webkit-flex-direction: row !important; }
/* #quarto-sidebar { padding: 5px; }
#quarto-sidebar > * { padding: 5px; }
div.sidebar-menu-container > * { padding: 5px 5px 5px 5px; }
#quarto-margin-sidebar { padding: 40px; } */
</style>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/index.html</guid>
  <pubDate>Fri, 24 Nov 2023 05:00:00 GMT</pubDate>
  <media:content url="https://nishantbharali.github.io/Blog/posts/Anomaly-Outlier Detection/Bnip.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Advanced Classification techniques with Model Prediction Analysis</title>
  <dc:creator>Nishant Bharali</dc:creator>
  <link>https://nishantbharali.github.io/Blog/posts/Classification/index.html</link>
  <description><![CDATA[ 



<section id="advanced-classification-techniques-with-model-prediction-analysis" class="level2">
<h2 class="anchored" data-anchor-id="advanced-classification-techniques-with-model-prediction-analysis">Advanced Classification techniques with Model Prediction Analysis</h2>
<p><strong>Implementing advanced classification techniques for precise model prediction analysis to enhance accuracy and efficiency</strong></p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Machine learning is a fascinating field that empowers computers to learn and make predictions or decisions without being explicitly programmed. One of the fundamental tasks in machine learning is classification, where the goal is to categorize data points into predefined classes or labels. In this blog post, we dive deep into the world of classification, exploring advanced techniques and their application on a real-world dataset.</p>
<p>The Iris dataset is a well-known benchmark in the machine learning community. It consists of measurements of four features from three different species of iris flowers. This seemingly simple dataset serves as an excellent playground for understanding and implementing classification algorithms. However, we won’t stop at the basics; we’ll explore advanced classification techniques, model tuning, and even dive into ensemble methods and neural networks.</p>
<p><strong>Data Loading and Preliminary Analysis</strong></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Importing essential libraries</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load dataset</span></span>
<span id="cb1-8">iris_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Iris_dataset.csv'</span>)</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Basic dataset information</span></span>
<span id="cb1-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(iris_df.head())</span>
<span id="cb1-12"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(iris_df.describe())</span>
<span id="cb1-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(iris_df.info())</span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualizing the distribution of classes</span></span>
<span id="cb1-16">sns.countplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris_df)</span>
<span id="cb1-17">plt.show()</span>
<span id="cb1-18"></span>
<span id="cb1-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pairplot to explore relationships between features</span></span>
<span id="cb1-20">sns.pairplot(iris_df, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>)</span>
<span id="cb1-21">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \
0           6.370695          2.771952           5.118790          1.542084   
1           5.979286          2.612095           5.086595          1.560228   
2           6.741563          2.804321           4.758669          1.443702   
3           6.346538          2.796799           5.601084          2.114922   
4           5.558280          2.831451           4.876331          2.045125   

      species  
0   virginica  
1  versicolor  
2  versicolor  
3   virginica  
4   virginica  
       sepal length (cm)  sepal width (cm)  petal length (cm)  \
count        3000.000000       3000.000000        3000.000000   
mean            5.844003          3.055776           3.756746   
std             0.825203          0.435899           1.761100   
min             4.180767          1.918769           0.907839   
25%             5.118694          2.780525           1.559288   
50%             5.777010          3.025634           4.347984   
75%             6.416866          3.342169           5.098831   
max             7.963257          4.516746           7.046886   

       petal width (cm)  
count       3000.000000  
mean           1.199022  
std            0.760822  
min           -0.048888  
25%            0.310048  
50%            1.326659  
75%            1.818514  
max            2.601413  
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 3000 entries, 0 to 2999
Data columns (total 5 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  3000 non-null   float64
 1   sepal width (cm)   3000 non-null   float64
 2   petal length (cm)  3000 non-null   float64
 3   petal width (cm)   3000 non-null   float64
 4   species            3000 non-null   object 
dtypes: float64(4), object(1)
memory usage: 117.3+ KB
None</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-2-output-2.png" width="601" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-2-output-3.png" width="1069" height="947"></p>
</div>
</div>
<p><strong>Data Preprocessing</strong></p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LabelEncoder, StandardScaler</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Encoding categorical data</span></span>
<span id="cb3-5">encoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LabelEncoder()</span>
<span id="cb3-6">iris_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encoder.fit_transform(iris_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>])</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Splitting dataset into features and target variable</span></span>
<span id="cb3-9">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris_df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-10">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>]</span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Splitting dataset into training and testing sets</span></span>
<span id="cb3-13">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb3-14"></span>
<span id="cb3-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feature scaling</span></span>
<span id="cb3-16">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb3-17">X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(X_train)</span>
<span id="cb3-18">X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.transform(X_test)</span></code></pre></div>
</div>
<p><strong>Exploratory Data Analysis (EDA)</strong></p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Correlation heatmap</span></span>
<span id="cb4-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb4-3">sns.heatmap(iris_df.corr(), annot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb4-4">plt.show()</span>
<span id="cb4-5"></span>
<span id="cb4-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Advanced pairplot with distribution and regression</span></span>
<span id="cb4-7">sns.pairplot(iris_df, kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reg'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>)</span>
<span id="cb4-8">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-4-output-1.png" width="745" height="638"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-4-output-2.png" width="1016" height="947"></p>
</div>
</div>
</section>
<section id="model-building-and-evaluation-for-classification" class="level2">
<h2 class="anchored" data-anchor-id="model-building-and-evaluation-for-classification">Model Building and Evaluation For Classification</h2>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> classification_report, confusion_matrix</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.tree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DecisionTreeClassifier</span>
<span id="cb5-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier, GradientBoostingClassifier</span>
<span id="cb5-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.svm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SVC</span>
<span id="cb5-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.neighbors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KNeighborsClassifier</span>
<span id="cb5-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to train and evaluate models</span></span>
<span id="cb5-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> train_evaluate_model(model, X_train, y_train, X_test, y_test):</span>
<span id="cb5-10">    model.fit(X_train, y_train)</span>
<span id="cb5-11">    predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_test)</span>
<span id="cb5-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Model: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>__class__<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb5-13">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, predictions))</span>
<span id="cb5-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Confusion matrix</span></span>
<span id="cb5-15">    cm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> confusion_matrix(y_test, predictions)</span>
<span id="cb5-16">    sns.heatmap(cm, annot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb5-17">    plt.show()</span>
<span id="cb5-18"></span>
<span id="cb5-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Decision Tree Classifier</span></span>
<span id="cb5-20">train_evaluate_model(DecisionTreeClassifier(), X_train, y_train, X_test, y_test)</span>
<span id="cb5-21"></span>
<span id="cb5-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># RandomForestClassifier</span></span>
<span id="cb5-23">train_evaluate_model(RandomForestClassifier(), X_train, y_train, X_test, y_test)</span>
<span id="cb5-24"></span>
<span id="cb5-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GradientBoostingClassifier</span></span>
<span id="cb5-26">train_evaluate_model(GradientBoostingClassifier(), X_train, y_train, X_test, y_test)</span>
<span id="cb5-27"></span>
<span id="cb5-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Support Vector Machine (SVC)</span></span>
<span id="cb5-29">train_evaluate_model(SVC(), X_train, y_train, X_test, y_test)</span>
<span id="cb5-30"></span>
<span id="cb5-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># K-Nearest Neighbors (KNN)</span></span>
<span id="cb5-32">train_evaluate_model(KNeighborsClassifier(), X_train, y_train, X_test, y_test)</span>
<span id="cb5-33"></span>
<span id="cb5-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Logistic Regression</span></span>
<span id="cb5-35">train_evaluate_model(LogisticRegression(), X_train, y_train, X_test, y_test)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: DecisionTreeClassifier
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       0.99      0.98      0.99       299
           2       0.98      0.99      0.99       312

    accuracy                           0.99       900
   macro avg       0.99      0.99      0.99       900
weighted avg       0.99      0.99      0.99       900

Model: RandomForestClassifier
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       0.99      0.99      0.99       299
           2       0.99      0.99      0.99       312

    accuracy                           1.00       900
   macro avg       1.00      1.00      1.00       900
weighted avg       1.00      1.00      1.00       900

Model: GradientBoostingClassifier
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       0.99      0.99      0.99       299
           2       0.99      0.99      0.99       312

    accuracy                           1.00       900
   macro avg       1.00      1.00      1.00       900
weighted avg       1.00      1.00      1.00       900

Model: SVC
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       0.99      0.96      0.98       299
           2       0.97      0.99      0.98       312

    accuracy                           0.98       900
   macro avg       0.99      0.98      0.98       900
weighted avg       0.98      0.98      0.98       900

Model: KNeighborsClassifier
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       1.00      1.00      1.00       299
           2       1.00      1.00      1.00       312

    accuracy                           1.00       900
   macro avg       1.00      1.00      1.00       900
weighted avg       1.00      1.00      1.00       900

Model: LogisticRegression
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       0.98      0.95      0.97       299
           2       0.96      0.98      0.97       312

    accuracy                           0.98       900
   macro avg       0.98      0.98      0.98       900
weighted avg       0.98      0.98      0.98       900
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-5-output-2.png" width="537" height="411"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-5-output-3.png" width="537" height="411"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-5-output-4.png" width="537" height="411"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-5-output-5.png" width="537" height="411"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-5-output-6.png" width="537" height="411"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-5-output-7.png" width="537" height="411"></p>
</div>
</div>
<p>In this code, we introduce different types of classification models, including Random Forest Classifier, Gradient Boosting Classifier, Support Vector Classifier (SVC), K-Nearest Neighbors Classifier (KNN), and Logistic Regression.</p>
<p>For each model, we train it on the training data and evaluate its performance using accuracy and a classification report that includes precision, recall, and F1-score. This allows you to compare the performance of various classification algorithms on the Iris dataset.</p>
<p><strong>Advanced Model Tuning and Analysis</strong></p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GridSearchCV</span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hyperparameter tuning for RandomForestClassifier</span></span>
<span id="cb7-4">param_grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n_estimators'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_features'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sqrt'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'log2'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]}</span>
<span id="cb7-5">grid_search <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GridSearchCV(RandomForestClassifier(), param_grid, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb7-6">grid_search.fit(X_train, y_train)</span>
<span id="cb7-7">best_rf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> grid_search.best_estimator_</span>
<span id="cb7-8"></span>
<span id="cb7-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluating the tuned model</span></span>
<span id="cb7-10">train_evaluate_model(best_rf, X_train, y_train, X_test, y_test)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: RandomForestClassifier
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       0.99      0.99      0.99       299
           2       0.99      0.99      0.99       312

    accuracy                           1.00       900
   macro avg       1.00      1.00      1.00       900
weighted avg       1.00      1.00      1.00       900
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-6-output-2.png" width="537" height="411"></p>
</div>
</div>
<p><strong>Hyperparameter Tuning for the Classification Model</strong></p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GridSearchCV</span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> classification_report, accuracy_score</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Proper Hyperparameter tuning for Random Forest Classifier</span></span>
<span id="cb9-5">param_grid_rf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb9-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n_estimators'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>],</span>
<span id="cb9-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>],</span>
<span id="cb9-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_split'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>],</span>
<span id="cb9-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_leaf'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span>
<span id="cb9-10">}</span>
<span id="cb9-11"></span>
<span id="cb9-12">grid_search_rf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GridSearchCV(RandomForestClassifier(), param_grid_rf, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb9-13">grid_search_rf.fit(X_train, y_train)</span>
<span id="cb9-14"></span>
<span id="cb9-15">best_rf_classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> grid_search_rf.best_estimator_</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluating the tuned Random Forest Classifier</span></span>
<span id="cb9-18">tuned_rf_predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> best_rf_classifier.predict(X_test)</span>
<span id="cb9-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Tuned Random Forest Classifier - Model Evaluation"</span>)</span>
<span id="cb9-20"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Accuracy:"</span>, accuracy_score(y_test, tuned_rf_predictions))</span>
<span id="cb9-21"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Classification Report:"</span>)</span>
<span id="cb9-22"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, tuned_rf_predictions))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tuned Random Forest Classifier - Model Evaluation
Accuracy: 0.9955555555555555
Classification Report:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       0.99      0.99      0.99       299
           2       0.99      0.99      0.99       312

    accuracy                           1.00       900
   macro avg       1.00      1.00      1.00       900
weighted avg       1.00      1.00      1.00       900
</code></pre>
</div>
</div>
</section>
<section id="roc-curve-analysis-for-multiple-models" class="level2">
<h2 class="anchored" data-anchor-id="roc-curve-analysis-for-multiple-models">ROC Curve Analysis for Multiple Models</h2>
<p>Comparing the performance of the various classification models using ROC Curve analysis, here we discuss the plots of the ROC Curve for each model. This will involve calculating the True Positive Rate (TPR) and False Positive Rate (FPR) for each model and plotting them.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> roc_curve, auc</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> label_binarize</span>
<span id="cb11-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.multiclass <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OneVsRestClassifier</span>
<span id="cb11-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb11-5"></span>
<span id="cb11-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Binarize the output classes for ROC analysis</span></span>
<span id="cb11-7">y_bin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> label_binarize(y, classes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb11-8">n_classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_bin.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Splitting the data again for multiclass ROC analysis</span></span>
<span id="cb11-11">X_train, X_test, y_train_bin, y_test_bin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y_bin, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Classifier list</span></span>
<span id="cb11-14">classifiers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb11-15">    OneVsRestClassifier(DecisionTreeClassifier()),</span>
<span id="cb11-16">    OneVsRestClassifier(RandomForestClassifier()),</span>
<span id="cb11-17">    OneVsRestClassifier(GradientBoostingClassifier()),</span>
<span id="cb11-18">    OneVsRestClassifier(SVC(probability<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)),</span>
<span id="cb11-19">    OneVsRestClassifier(KNeighborsClassifier()),</span>
<span id="cb11-20">    OneVsRestClassifier(LogisticRegression())</span>
<span id="cb11-21">]</span>
<span id="cb11-22"></span>
<span id="cb11-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plotting ROC Curves</span></span>
<span id="cb11-24">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb11-25"></span>
<span id="cb11-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute ROC curve and ROC area for each class</span></span>
<span id="cb11-27"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> classifier <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> classifiers:</span>
<span id="cb11-28">    classifier.fit(X_train, y_train_bin)</span>
<span id="cb11-29">    y_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier.predict_proba(X_test)</span>
<span id="cb11-30"></span>
<span id="cb11-31">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute ROC curve and ROC area for each class</span></span>
<span id="cb11-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_classes):</span>
<span id="cb11-33">        fpr, tpr, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_curve(y_test_bin[:, i], y_score[:, i])</span>
<span id="cb11-34">        roc_auc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> auc(fpr, tpr)</span>
<span id="cb11-35">        plt.plot(fpr, tpr, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>classifier<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>estimator<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>__class__<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> (area = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>roc_auc<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)'</span>)</span>
<span id="cb11-36"></span>
<span id="cb11-37">plt.plot([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k--'</span>)</span>
<span id="cb11-38">plt.xlim([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>])</span>
<span id="cb11-39">plt.ylim([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.05</span>])</span>
<span id="cb11-40">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'False Positive Rate'</span>)</span>
<span id="cb11-41">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Positive Rate'</span>)</span>
<span id="cb11-42">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Receiver Operating Characteristic for Multi-class'</span>)</span>
<span id="cb11-43">plt.legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lower right"</span>)</span>
<span id="cb11-44">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-8-output-1.png" width="823" height="671"></p>
</div>
</div>
<p>This code will generate ROC curves for each of the classifiers used, providing a visual comparison of their performance in terms of the trade-off between the True Positive Rate and False Positive Rate. The area under the curve (AUC) is also displayed as a measure of the model’s performance, with a higher AUC indicating a better model. This analysis is crucial for understanding the performance of classification models, especially in multi-class settings.</p>
<p><strong>Dimensionality Reduction and Visualization</strong></p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.decomposition <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PCA</span>
<span id="cb12-2"></span>
<span id="cb12-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PCA for dimensionality reduction</span></span>
<span id="cb12-4">pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PCA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb12-5">X_train_pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca.fit_transform(X_train)</span>
<span id="cb12-6">X_test_pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca.transform(X_test)</span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualizing PCA results</span></span>
<span id="cb12-9">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb12-10">plt.scatter(X_train_pca[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X_train_pca[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_train, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Train set'</span>)</span>
<span id="cb12-11">plt.scatter(X_test_pca[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X_test_pca[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_test, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'plasma'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Test set'</span>, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>)</span>
<span id="cb12-12">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'First principal component'</span>)</span>
<span id="cb12-13">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Second principal component'</span>)</span>
<span id="cb12-14">plt.legend()</span>
<span id="cb12-15">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PCA of Iris Dataset'</span>)</span>
<span id="cb12-16">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-9-output-1.png" width="674" height="523"></p>
</div>
</div>
</section>
<section id="additional-advanced-analysis" class="level2">
<h2 class="anchored" data-anchor-id="additional-advanced-analysis">Additional Advanced Analysis</h2>
<p><strong>1. Cross-Validation</strong></p>
<p>Cross-validation is a technique used to evaluate the generalizability of a model by training and testing it on different subsets of the dataset.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cross_val_score</span>
<span id="cb13-2"></span>
<span id="cb13-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example using RandomForestClassifier</span></span>
<span id="cb13-4">rf_classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier()</span>
<span id="cb13-5"></span>
<span id="cb13-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Performing 10-fold cross-validation</span></span>
<span id="cb13-7">cv_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cross_val_score(rf_classifier, X, y, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb13-8"></span>
<span id="cb13-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cross-Validation Scores for RandomForestClassifier:"</span>, cv_scores)</span>
<span id="cb13-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Average Score:"</span>, np.mean(cv_scores))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cross-Validation Scores for RandomForestClassifier: [0.99666667 1.         0.99333333 0.99333333 1.         0.99666667
 0.99666667 0.99333333 1.         1.        ]
Average Score: 0.9969999999999999</code></pre>
</div>
</div>
<p><strong>2. Ensemble Methods</strong></p>
<p>Ensemble methods combine multiple models to improve the overall performance. Here, I will use an ensemble of different classifiers.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb15-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> VotingClassifier</span>
<span id="cb15-3"></span>
<span id="cb15-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update Logistic Regression in the ensemble</span></span>
<span id="cb15-5">classifiers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb15-6">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Decision Tree'</span>, DecisionTreeClassifier()),</span>
<span id="cb15-7">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Random Forest'</span>, RandomForestClassifier()),</span>
<span id="cb15-8">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Gradient Boosting'</span>, GradientBoostingClassifier()),</span>
<span id="cb15-9">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SVC'</span>, SVC(probability<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)),</span>
<span id="cb15-10">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KNN'</span>, KNeighborsClassifier()),</span>
<span id="cb15-11">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Logistic Regression'</span>, LogisticRegression(max_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>))</span>
<span id="cb15-12">]</span>
<span id="cb15-13"></span>
<span id="cb15-14">ensemble <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> VotingClassifier(estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>classifiers, voting<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'soft'</span>)</span>
<span id="cb15-15">ensemble.fit(X_train, y_train)</span>
<span id="cb15-16">ensemble_predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ensemble.predict(X_test)</span>
<span id="cb15-17"></span>
<span id="cb15-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Ensemble Model Classification Report:"</span>)</span>
<span id="cb15-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, ensemble_predictions))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ensemble Model Classification Report:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       289
           1       1.00      0.99      0.99       299
           2       0.99      1.00      1.00       312

    accuracy                           1.00       900
   macro avg       1.00      1.00      1.00       900
weighted avg       1.00      1.00      1.00       900
</code></pre>
</div>
</div>
</section>
<section id="prediction" class="level2">
<h2 class="anchored" data-anchor-id="prediction">PREDICTION</h2>
<p><strong>Prediction: Data Preprocessing with Visualization</strong></p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb17-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LabelEncoder, StandardScaler</span>
<span id="cb17-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb17-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb17-5"></span>
<span id="cb17-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Encoding categorical data</span></span>
<span id="cb17-7">encoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LabelEncoder()</span>
<span id="cb17-8">iris_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encoder.fit_transform(iris_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>])</span>
<span id="cb17-9"></span>
<span id="cb17-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualizing the distribution of the target variable</span></span>
<span id="cb17-11">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb17-12">sns.countplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris_df)</span>
<span id="cb17-13">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distribution of Target Variable (Species)'</span>)</span>
<span id="cb17-14">plt.show()</span>
<span id="cb17-15"></span>
<span id="cb17-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Splitting dataset into features and target variable</span></span>
<span id="cb17-17">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris_df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb17-18">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>]</span>
<span id="cb17-19"></span>
<span id="cb17-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Splitting dataset into training and testing sets</span></span>
<span id="cb17-21">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb17-22"></span>
<span id="cb17-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feature scaling</span></span>
<span id="cb17-24">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb17-25">X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(X_train)</span>
<span id="cb17-26">X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.transform(X_test)</span>
<span id="cb17-27"></span>
<span id="cb17-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pairplot to explore relationships between features</span></span>
<span id="cb17-29">pairplot_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris_df.copy()</span>
<span id="cb17-30">pairplot_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encoder.inverse_transform(pairplot_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>])</span>
<span id="cb17-31"></span>
<span id="cb17-32">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb17-33">sns.pairplot(pairplot_df, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>)</span>
<span id="cb17-34">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Pairplot of Features with Species as Hue'</span>)</span>
<span id="cb17-35">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-12-output-1.png" width="676" height="449"></p>
</div>
<div class="cell-output cell-output-display">
<pre><code>&lt;Figure size 960x768 with 0 Axes&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-12-output-3.png" width="1016" height="947"></p>
</div>
</div>
</section>
<section id="model-building-evaluation-and-visualization-for-prediction" class="level2">
<h2 class="anchored" data-anchor-id="model-building-evaluation-and-visualization-for-prediction">Model Building, Evaluation, and Visualization for Prediction</h2>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error, r2_score</span>
<span id="cb19-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb19-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.tree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DecisionTreeRegressor</span>
<span id="cb19-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestRegressor</span>
<span id="cb19-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb19-6"></span>
<span id="cb19-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to train and evaluate regression models</span></span>
<span id="cb19-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> train_evaluate_regression_model(model, X_train, y_train, X_test, y_test):</span>
<span id="cb19-9">    model.fit(X_train, y_train)</span>
<span id="cb19-10">    predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_test)</span>
<span id="cb19-11">    </span>
<span id="cb19-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Model Evaluation</span></span>
<span id="cb19-13">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Model: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>__class__<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb19-14">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Mean Squared Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mean_squared_error(y_test, predictions)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb19-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'R-squared (R2) Score: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>r2_score(y_test, predictions)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb19-16">    </span>
<span id="cb19-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualization</span></span>
<span id="cb19-18">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb19-19">    plt.scatter(y_test, predictions)</span>
<span id="cb19-20">    plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Values'</span>)</span>
<span id="cb19-21">    plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predictions'</span>)</span>
<span id="cb19-22">    plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>__class__<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> - True vs. Predicted Values'</span>)</span>
<span id="cb19-23">    plt.show()</span>
<span id="cb19-24"></span>
<span id="cb19-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Linear Regression</span></span>
<span id="cb19-26">train_evaluate_regression_model(LinearRegression(), X_train, y_train, X_test, y_test)</span>
<span id="cb19-27"></span>
<span id="cb19-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Decision Tree Regressor</span></span>
<span id="cb19-29">train_evaluate_regression_model(DecisionTreeRegressor(), X_train, y_train, X_test, y_test)</span>
<span id="cb19-30"></span>
<span id="cb19-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Random Forest Regressor</span></span>
<span id="cb19-32">train_evaluate_regression_model(RandomForestRegressor(), X_train, y_train, X_test, y_test)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: LinearRegression
Mean Squared Error: 0.047703003079178956
R-squared (R2) Score: 0.9284946222241109
Model: DecisionTreeRegressor
Mean Squared Error: 0.0077777777777777776
R-squared (R2) Score: 0.9883413432623143
Model: RandomForestRegressor
Mean Squared Error: 0.006041444444444443
R-squared (R2) Score: 0.990944055102883</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-13-output-2.png" width="663" height="449"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-13-output-3.png" width="672" height="449"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-13-output-4.png" width="672" height="449"></p>
</div>
</div>
<p><strong>Advanced Model Tuning and Analysis for Prediction</strong></p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GridSearchCV</span>
<span id="cb21-2"></span>
<span id="cb21-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hyperparameter tuning for Random Forest Regressor</span></span>
<span id="cb21-4">param_grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb21-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n_estimators'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>],</span>
<span id="cb21-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>],</span>
<span id="cb21-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_split'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>],</span>
<span id="cb21-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_leaf'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span>
<span id="cb21-9">}</span>
<span id="cb21-10"></span>
<span id="cb21-11">grid_search <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GridSearchCV(RandomForestRegressor(), param_grid, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, scoring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'neg_mean_squared_error'</span>)</span>
<span id="cb21-12">grid_search.fit(X_train, y_train)</span>
<span id="cb21-13"></span>
<span id="cb21-14">best_rf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> grid_search.best_estimator_</span>
<span id="cb21-15"></span>
<span id="cb21-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluating the tuned model</span></span>
<span id="cb21-17">predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> best_rf.predict(X_test)</span>
<span id="cb21-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Tuned Random Forest Regressor - Model Evaluation"</span>)</span>
<span id="cb21-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Mean Squared Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mean_squared_error(y_test, predictions)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb21-20"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'R-squared (R2) Score: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>r2_score(y_test, predictions)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tuned Random Forest Regressor - Model Evaluation
Mean Squared Error: 0.0072306666666666665
R-squared (R2) Score: 0.9891614464876909</code></pre>
</div>
</div>
<p><strong>Feature Selection and Importance Analysis</strong></p>
<p>Feature selection is crucial for improving model performance and reducing overfitting. Here, we use techniques like Recursive Feature Elimination (RFE) and feature importance analysis to select the most relevant features for classification or prediction.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.feature_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RFE</span>
<span id="cb23-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb23-3"></span>
<span id="cb23-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Using Recursive Feature Elimination (RFE) with Logistic Regression</span></span>
<span id="cb23-5">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LogisticRegression()</span>
<span id="cb23-6">rfe <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RFE(model, n_features_to_select<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Select the top 3 features</span></span>
<span id="cb23-7">fit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rfe.fit(X_train, y_train)</span>
<span id="cb23-8"></span>
<span id="cb23-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># List of selected features</span></span>
<span id="cb23-10">selected_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [feature <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> idx, feature <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(X.columns) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> fit.support_[idx]]</span>
<span id="cb23-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Selected Features:"</span>, selected_features)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Selected Features: ['sepal width (cm)', 'petal length (cm)', 'petal width (cm)']</code></pre>
</div>
</div>
<p>Additionally, we can analyze feature importance for tree-based models like Random Forest or Gradient Boosting to understand which features contribute the most to predictions.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier</span>
<span id="cb25-2"></span>
<span id="cb25-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feature Importance Analysis for Random Forest Classifier</span></span>
<span id="cb25-4">rf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier()</span>
<span id="cb25-5">rf_model.fit(X_train, y_train)</span>
<span id="cb25-6"></span>
<span id="cb25-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot feature importance</span></span>
<span id="cb25-8">feature_importance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series(rf_model.feature_importances_, index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X.columns)</span>
<span id="cb25-9">feature_importance.nlargest(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>).plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'barh'</span>)</span>
<span id="cb25-10">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Feature Importance (Random Forest)"</span>)</span>
<span id="cb25-11">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Classification/index_files/figure-html/cell-16-output-1.png" width="666" height="431"></p>
</div>
</div>
<p><strong>Handling Class Imbalance</strong></p>
<p>In real-world datasets, class imbalance is common, where one class has significantly fewer samples than others. Techniques like oversampling, undersampling, and Synthetic Minority Over-sampling Technique (SMOTE) can be employed to address this issue.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> imblearn.over_sampling <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SMOTE</span>
<span id="cb26-2"></span>
<span id="cb26-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Using SMOTE to handle class imbalance</span></span>
<span id="cb26-4">smote <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SMOTE(sampling_strategy<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auto'</span>)</span>
<span id="cb26-5">X_train_resampled, y_train_resampled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> smote.fit_resample(X_train, y_train)</span></code></pre></div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this journey through the Iris dataset and the realm of classification, we’ve covered a wide range of topics. Starting with data loading and preprocessing, we explored the relationships between features, ensuring that we understood our data thoroughly. We then introduced a variety of classification models, from decision trees to support vector machines, and compared their performance using robust evaluation metrics.</p>
<p>But we didn’t stop there. We delved into advanced techniques, including cross-validation to ensure the generalizability of our models, ensemble methods that combined the strengths of multiple classifiers, and even a taste of neural networks for classification tasks.</p>
<p>Our exploration of ROC curves allowed us to visualize and compare the trade-offs between true positive and false positive rates across different models, providing valuable insights into their performance.</p>
<p>In the end, classification is a powerful tool in the machine learning toolkit, with applications ranging from medical diagnosis to spam email filtering. The Iris dataset served as an ideal playground to learn and experiment with these techniques, but the knowledge gained can be applied to more complex and real-world classification problems.</p>
<p>As you continue your journey in machine learning, remember that classification is just the tip of the iceberg. The world of machine learning is vast and ever-evolving, and there are countless exciting challenges and opportunities awaiting those who dare to explore it further.</p>
<script>
const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
</script>
<style>
div#quarto-sidebar-glass { display: none !important; }
ul.navbar-nav.navbar-nav-scroll { -webkit-flex-direction: row !important; }
/* #quarto-sidebar { padding: 5px; }
#quarto-sidebar > * { padding: 5px; }
div.sidebar-menu-container > * { padding: 5px 5px 5px 5px; }
#quarto-margin-sidebar { padding: 40px; } */
</style>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://nishantbharali.github.io/Blog/posts/Classification/index.html</guid>
  <pubDate>Fri, 24 Nov 2023 05:00:00 GMT</pubDate>
  <media:content url="https://nishantbharali.github.io/Blog/posts/Classification/Rz0T.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Advanced Clustering and Prediction techniques</title>
  <dc:creator>Nishant Bharali</dc:creator>
  <link>https://nishantbharali.github.io/Blog/posts/Clustering/index.html</link>
  <description><![CDATA[ 



<section id="advanced-clustering-and-prediction-techniques-using-retail-customer-data" class="level4">
<h4 class="anchored" data-anchor-id="advanced-clustering-and-prediction-techniques-using-retail-customer-data">Advanced Clustering and Prediction techniques Using Retail Customer Data</h4>
<p><strong>Employing sophisticated clustering techniques with retail customer data and comparing further with prediction models</strong></p>
<p>Clustering is a fundamental technique in machine learning that involves grouping data points so that the objects in the same group (or cluster) are more similar to each other than to those in other groups. It’s a form of unsupervised learning, as the groups are not predefined but rather determined by the algorithm itself. This approach is particularly useful in understanding the structure within data, identifying patterns, and making strategic decisions.</p>
<p>In this blog, we will explore how to apply clustering techniques to a customer dataset. Our dataset contains customer information with attributes like Customer ID, Age, Annual Income, and Spending Score. The goal is to segment customers into distinct groups based on these features, which can help in tailoring marketing strategies, understanding customer behavior, and improving customer service.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p><strong>Data Loading and Basic Visualization</strong></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Importing libraries</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KMeans</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the dataset</span></span>
<span id="cb1-9">customer_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clusteringCustomerData.csv'</span>)</span>
<span id="cb1-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(customer_df.head())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   CustomerID  Age  Annual_Income  Spending_Score
0           1   62             75              81
1           2   65             76              23
2           3   18             98              80
3           4   21             48              90
4           5   21             47               9</code></pre>
</div>
</div>
<p><strong>Exploring Data Analysis</strong></p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Visualize the distributions and relationships between features.</span></span>
<span id="cb3-2">sns.pairplot(customer_df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'CustomerID'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb3-3">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-3-output-1.png" width="711" height="711"></p>
</div>
</div>
<p><strong>Data Preprocessing</strong></p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Encoding categorical data and scaling features.</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Standardize the data.</span></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Selecting features to be scaled</span></span>
<span id="cb4-4">features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> customer_df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Annual_Income'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spending_Score'</span>]]</span>
<span id="cb4-5"></span>
<span id="cb4-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Standardizing the features</span></span>
<span id="cb4-7">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb4-8">scaled_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(features)</span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Converting scaled features back to a DataFrame</span></span>
<span id="cb4-11">scaled_features_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(scaled_features, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>features.columns)</span>
<span id="cb4-12"></span>
<span id="cb4-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Displaying the first few rows of the scaled data</span></span>
<span id="cb4-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(scaled_features_df.head())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        Age  Annual_Income  Spending_Score
0  1.237684       0.746278        0.901945
1  1.428146       0.788416       -1.020966
2 -1.555756       1.715469        0.868791
3 -1.365294      -0.391469        1.200327
4 -1.365294      -0.433608       -1.485117</code></pre>
</div>
</div>
<p><strong>Exploratory Data Analysis (EDA)</strong></p>
<p>Beyond basic visualizations, we’ll use EDA to understand the data distributions and potential relationships.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualizing the distribution of features</span></span>
<span id="cb6-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb6-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, col <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Annual_Income'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spending_Score'</span>]):</span>
<span id="cb6-4">    plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-5">    sns.histplot(customer_df[col], kde<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb6-6">    plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Distribution of </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>col<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb6-7">plt.tight_layout()</span>
<span id="cb6-8">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-5-output-1.png" width="1141" height="374"></p>
</div>
</div>
</section>
<section id="advanced-clustering-with-multiple-techniques" class="level2">
<h2 class="anchored" data-anchor-id="advanced-clustering-with-multiple-techniques">Advanced Clustering with Multiple Techniques</h2>
<p>We’ll explore different clustering algorithms beyond K-Means, such as Hierarchical Clustering and DBSCAN, to understand how they segment the data differently.</p>
<p><strong>1. K-Means Clustering</strong></p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Using the Elbow Method to determine the optimal number of clusters.</span></span>
<span id="cb7-2">wcss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb7-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>):</span>
<span id="cb7-4">    kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i, n_init<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb7-5">    kmeans.fit(scaled_features)</span>
<span id="cb7-6">    wcss.append(kmeans.inertia_)</span>
<span id="cb7-7">    customer_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KMeans_Cluster'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.labels_</span>
<span id="cb7-8">plt.plot(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>), wcss)</span>
<span id="cb7-9">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'The Elbow Method'</span>)</span>
<span id="cb7-10">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Number of clusters'</span>)</span>
<span id="cb7-11">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'WCSS'</span>)</span>
<span id="cb7-12">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-6-output-1.png" width="593" height="449"></p>
</div>
</div>
<p><strong>Application of K-Means</strong></p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Applying K-Means and visualizing the clusters.</span></span>
<span id="cb8-2">kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, n_init<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb8-3">customer_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cluster'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.fit_predict(scaled_features)</span>
<span id="cb8-4">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Annual_Income'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spending_Score'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cluster'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>customer_df, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb8-5">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Customer Segments'</span>)</span>
<span id="cb8-6">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-7-output-1.png" width="593" height="449"></p>
</div>
</div>
<p><strong>K-Means Visualization</strong></p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">sns.pairplot(customer_df, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">vars</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Annual_Income'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spending_Score'</span>], hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KMeans_Cluster'</span>, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb9-2">plt.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K-Means Clustering'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.02</span>)</span>
<span id="cb9-3">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-8-output-1.png" width="834" height="740"></p>
</div>
</div>
<p><strong>2. DBSCAN clustering</strong></p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DBSCAN</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># DBSCAN clustering</span></span>
<span id="cb10-4">dbscan <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DBSCAN(eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, min_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>).fit(scaled_features_df)</span>
<span id="cb10-5">customer_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'DBSCAN_Cluster'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dbscan.labels_</span></code></pre></div>
</div>
<p><strong>Density-Based Spatial Clustering of Applications with Noise (DBSCAN) Visualization</strong></p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualizing DBSCAN Clusters</span></span>
<span id="cb11-2">sns.scatterplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Annual_Income'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spending_Score'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'DBSCAN_Cluster'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>customer_df, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb11-3">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'DBSCAN Clustering'</span>)</span>
<span id="cb11-4">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-10-output-1.png" width="593" height="449"></p>
</div>
</div>
<p><strong>3. Hierarchical Cluster Visualization</strong></p>
<p>Visualize the clusters formed by each algorithm in multiple dimensions to gain deeper insights.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.cluster.hierarchy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dendrogram, linkage</span>
<span id="cb12-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AgglomerativeClustering  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import AgglomerativeClustering</span></span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Performing Hierarchical Clustering</span></span>
<span id="cb12-5">linked <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linkage(scaled_features_df, method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ward'</span>)</span>
<span id="cb12-6"></span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plotting the Dendrogram</span></span>
<span id="cb12-8">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb12-9">dendrogram(linked, orientation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'top'</span>, distance_sort<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'descending'</span>, show_leaf_counts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb12-10">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hierarchical Clustering Dendrogram'</span>)</span>
<span id="cb12-11">plt.show()</span>
<span id="cb12-12"></span>
<span id="cb12-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform hierarchical clustering and add the cluster labels to customer_df</span></span>
<span id="cb12-14">clustering <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgglomerativeClustering(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Specify the number of clusters</span></span>
<span id="cb12-15">customer_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hierarchical_Cluster'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clustering.fit_predict(scaled_features_df)</span>
<span id="cb12-16"></span>
<span id="cb12-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hierarchical Clustering Visualization</span></span>
<span id="cb12-18">sns.pairplot(customer_df, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">vars</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Annual_Income'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spending_Score'</span>], hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hierarchical_Cluster'</span>, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb12-19">plt.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hierarchical Clustering'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.02</span>)</span>
<span id="cb12-20">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-11-output-1.png" width="804" height="579"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-11-output-2.png" width="862" height="740"></p>
</div>
</div>
<p><strong>Hierarchical Clustering Cut</strong></p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.cluster.hierarchy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> fcluster</span>
<span id="cb13-2"></span>
<span id="cb13-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Cutting the Dendrogram to form clusters</span></span>
<span id="cb13-4">customer_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hierarchical_Cluster'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fcluster(linked, t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, criterion<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'maxclust'</span>)</span>
<span id="cb13-5"></span>
<span id="cb13-6">sns.scatterplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>customer_df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Annual_Income'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spending_Score'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hierarchical_Cluster'</span>, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb13-7">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hierarchical Clustering'</span>)</span>
<span id="cb13-8">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-12-output-1.png" width="593" height="449"></p>
</div>
</div>
</section>
<section id="silhouette-analysis-for-k-means-and-hierarchical-clustering" class="level2">
<h2 class="anchored" data-anchor-id="silhouette-analysis-for-k-means-and-hierarchical-clustering">Silhouette Analysis for K-means and Hierarchical Clustering</h2>
<p><strong>1. K-Means Clustering</strong></p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> silhouette_samples, silhouette_score</span>
<span id="cb14-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate silhouette scores for different cluster numbers</span></span>
<span id="cb14-5">silhouette_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> n_clusters <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>):</span>
<span id="cb14-7">    kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_clusters, n_init<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb14-8">    cluster_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.fit_predict(scaled_features)</span>
<span id="cb14-9">    silhouette_avg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> silhouette_score(scaled_features, cluster_labels)</span>
<span id="cb14-10">    silhouette_scores.append(silhouette_avg)</span>
<span id="cb14-11"></span>
<span id="cb14-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot silhouette scores</span></span>
<span id="cb14-13">plt.plot(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>), silhouette_scores, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>)</span>
<span id="cb14-14">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Silhouette Analysis for K-Means'</span>)</span>
<span id="cb14-15">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Number of clusters'</span>)</span>
<span id="cb14-16">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Silhouette Score'</span>)</span>
<span id="cb14-17">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-13-output-1.png" width="597" height="449"></p>
</div>
</div>
<p><strong>2. Hierarchical Clustering</strong></p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AgglomerativeClustering</span>
<span id="cb15-2"></span>
<span id="cb15-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate silhouette scores for different cluster numbers in hierarchical clustering</span></span>
<span id="cb15-4">silhouette_scores_hierarchical <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb15-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> n_clusters <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>):</span>
<span id="cb15-6">    hierarchical <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgglomerativeClustering(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_clusters)</span>
<span id="cb15-7">    cluster_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> hierarchical.fit_predict(scaled_features)</span>
<span id="cb15-8">    silhouette_avg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> silhouette_score(scaled_features, cluster_labels)</span>
<span id="cb15-9">    silhouette_scores_hierarchical.append(silhouette_avg)</span>
<span id="cb15-10"></span>
<span id="cb15-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot silhouette scores for hierarchical clustering</span></span>
<span id="cb15-12">plt.plot(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>), silhouette_scores_hierarchical, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>)</span>
<span id="cb15-13">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Silhouette Analysis for Hierarchical Clustering'</span>)</span>
<span id="cb15-14">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Number of clusters'</span>)</span>
<span id="cb15-15">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Silhouette Score'</span>)</span>
<span id="cb15-16">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Clustering/index_files/figure-html/cell-14-output-1.png" width="606" height="449"></p>
</div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>#In this in-depth analysis, we have explored different clustering techniques and visualized their results to segment customers in a comprehensive manner. Each method offers unique insights: K-Means provides clear segmentations, Hierarchical Clustering helps us understand the data structure, and DBSCAN identifies core and outlier points effectively.</p>
<p>By comparing these methods, we can choose the one that best suits our specific needs for customer segmentation. This advanced clustering analysis can guide strategic decisions, improve customer engagement, and enhance targeting in marketing campaigns.</p>
<script>
const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
</script>
<style>
div#quarto-sidebar-glass { display: none !important; }
ul.navbar-nav.navbar-nav-scroll { -webkit-flex-direction: row !important; }
/* #quarto-sidebar { padding: 5px; }
#quarto-sidebar > * { padding: 5px; }
div.sidebar-menu-container > * { padding: 5px 5px 5px 5px; }
#quarto-margin-sidebar { padding: 40px; } */
</style>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://nishantbharali.github.io/Blog/posts/Clustering/index.html</guid>
  <pubDate>Fri, 24 Nov 2023 05:00:00 GMT</pubDate>
  <media:content url="https://nishantbharali.github.io/Blog/posts/Clustering/E3K6.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Advanced analysis on Linear and Non-Linear Regression models</title>
  <dc:creator>Nishant Bharali</dc:creator>
  <link>https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index.html</link>
  <description><![CDATA[ 



<section id="a-comprehensive-analysis-on-housing-market" class="level2">
<h2 class="anchored" data-anchor-id="a-comprehensive-analysis-on-housing-market">A Comprehensive Analysis on Housing Market</h2>
<p><strong>Utilizing linear and non-linear regression methodologies for the purpose of analyzing trends within the housing market</strong></p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In machine learning, linear and nonlinear regression are fundamental techniques used to model relationships between variables, such as predicting housing prices based on various features in a dataset.</p>
<p>Linear Regression is a straightforward method that assumes a linear relationship between the input features (e.g., square footage, number of bedrooms) and the target variable (housing price). It aims to find the best-fit line that minimizes the difference between predicted and actual values. Linear regression is interpretable and works well when the relationship is approximately linear.</p>
<p>Nonlinear Regression, on the other hand, allows for more complex relationships. It can capture curves, bends, and nonlinear patterns in the data. This is particularly useful when housing prices may depend on interactions between features or exhibit nonlinear behavior.</p>
<p>The housing dataset you are using provides a rich source of information to apply both linear and nonlinear regression techniques. By utilizing these methods, you can build predictive models that estimate housing prices accurately, taking into account the specific relationships between features and target variables, whether they are linear or nonlinear in nature. These models can guide real estate decisions, investment strategies, and market analyses more effectively, ultimately benefiting both buyers and sellers in the housing market.</p>
<p>We will start by loading the dataset and performing basic preprocessing, including encoding categorical variables and feature scaling.</p>
<p><strong>Exploring the Dataset and Data Preprocessing</strong></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.impute <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SimpleImputer</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.compose <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ColumnTransformer</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.pipeline <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Pipeline</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sm</span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb1-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error, r2_score</span>
<span id="cb1-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cross_val_score</span>
<span id="cb1-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestRegressor</span>
<span id="cb1-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GridSearchCV</span>
<span id="cb1-17"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PolynomialFeatures</span>
<span id="cb1-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> learning_curve</span>
<span id="cb1-19"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GradientBoostingRegressor</span>
<span id="cb1-20"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.svm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SVR</span>
<span id="cb1-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.neural_network <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MLPRegressor</span>
<span id="cb1-22"></span>
<span id="cb1-23"></span>
<span id="cb1-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the dataset</span></span>
<span id="cb1-25">housing_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'modified_housing_data.csv'</span>)</span>
<span id="cb1-26"></span>
<span id="cb1-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Handling missing values if any</span></span>
<span id="cb1-28">imputer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SimpleImputer(strategy<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>)</span>
<span id="cb1-29">housing_df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Size'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'GardenArea'</span>]] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> imputer.fit_transform(housing_df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Size'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'GardenArea'</span>]])</span>
<span id="cb1-30"></span>
<span id="cb1-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># One-hot encoding and Scaling</span></span>
<span id="cb1-32">categorical_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neighborhood'</span>]</span>
<span id="cb1-33">numerical_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Size'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Bedrooms'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Bathrooms'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'GarageSize'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'GardenArea'</span>]</span>
<span id="cb1-34"></span>
<span id="cb1-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create transformers</span></span>
<span id="cb1-36">one_hot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OneHotEncoder()</span>
<span id="cb1-37">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb1-38"></span>
<span id="cb1-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Column transformer</span></span>
<span id="cb1-40">preprocessor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ColumnTransformer(</span>
<span id="cb1-41">    transformers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb1-42">        (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num'</span>, scaler, numerical_features),</span>
<span id="cb1-43">        (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cat'</span>, one_hot, categorical_features)</span>
<span id="cb1-44">    ])</span>
<span id="cb1-45"></span>
<span id="cb1-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Preprocessing pipeline</span></span>
<span id="cb1-47">prep_pipeline <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Pipeline(steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'preprocessor'</span>, preprocessor)])</span>
<span id="cb1-48"></span>
<span id="cb1-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Splitting the data</span></span>
<span id="cb1-50">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> housing_df.drop([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'HouseID'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Price'</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-51">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> housing_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Price'</span>]</span>
<span id="cb1-52">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-53"></span>
<span id="cb1-54">X_train_prep <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prep_pipeline.fit_transform(X_train)</span>
<span id="cb1-55">X_test_prep <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prep_pipeline.transform(X_test)</span></code></pre></div>
</div>
<p><strong>Visualizing Market Trend</strong></p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Visualizing the distributions and relationships</span></span>
<span id="cb2-2">sns.pairplot(housing_df)</span>
<span id="cb2-3">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index_files/figure-html/cell-3-output-1.png" width="1887" height="1887"></p>
</div>
</div>
</section>
<section id="advanced-linear-regression-analysis" class="level2">
<h2 class="anchored" data-anchor-id="advanced-linear-regression-analysis">Advanced Linear Regression Analysis</h2>
<p>For the linear regression model, we’ll include feature importance analysis and cross-validation.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Linear Regression Model</span></span>
<span id="cb3-2">linear_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb3-3">linear_model.fit(X_train_prep, y_train)</span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Cross-Validation</span></span>
<span id="cb3-6">cv_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cross_val_score(linear_model, X_train_prep, y_train, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, scoring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'neg_mean_squared_error'</span>)</span>
<span id="cb3-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CV MSE for Linear Regression:"</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.mean(cv_scores))</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predictions and Evaluation</span></span>
<span id="cb3-10">y_pred_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linear_model.predict(X_test_prep)</span>
<span id="cb3-11">mse_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_linear)</span>
<span id="cb3-12">r2_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> r2_score(y_test, y_pred_linear)</span>
<span id="cb3-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Linear Regression Test MSE:"</span>, mse_linear)</span>
<span id="cb3-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Linear Regression Test R2:"</span>, r2_linear)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CV MSE for Linear Regression: 2618960221.1247973
Linear Regression Test MSE: 2520672652.9396286
Linear Regression Test R2: 0.9111757572070075</code></pre>
</div>
</div>
</section>
<section id="advanced-non-linear-regression-analysis" class="level2">
<h2 class="anchored" data-anchor-id="advanced-non-linear-regression-analysis">Advanced Non-Linear Regression Analysis</h2>
<p>We’ll apply a more complex non-linear model, such as a Random Forest Regressor, and perform hyperparameter tuning using GridSearchCV.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Non-Linear Model - Random Forest Regressor</span></span>
<span id="cb5-2">rf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestRegressor(random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hyperparameter Grid</span></span>
<span id="cb5-5">param_grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb5-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n_estimators'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>],</span>
<span id="cb5-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_features'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sqrt'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'log2'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Removed 'auto' and added None</span></span>
<span id="cb5-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>],</span>
<span id="cb5-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_split'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>],</span>
<span id="cb5-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_leaf'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span>
<span id="cb5-11">}</span>
<span id="cb5-12"></span>
<span id="cb5-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Grid Search</span></span>
<span id="cb5-14">grid_search <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GridSearchCV(estimator<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>rf_model, param_grid<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>param_grid, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, n_jobs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, scoring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'neg_mean_squared_error'</span>, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb5-15">grid_search.fit(X_train_prep, y_train)</span>
<span id="cb5-16"></span>
<span id="cb5-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Best Model</span></span>
<span id="cb5-18">best_rf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> grid_search.best_estimator_</span>
<span id="cb5-19"></span>
<span id="cb5-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predictions and Evaluation</span></span>
<span id="cb5-21">y_pred_rf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> best_rf_model.predict(X_test_prep)</span>
<span id="cb5-22">mse_rf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_rf)</span>
<span id="cb5-23">r2_rf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> r2_score(y_test, y_pred_rf)</span>
<span id="cb5-24"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Random Forest Test MSE:"</span>, mse_rf)</span>
<span id="cb5-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Random Forest Test R2:"</span>, r2_rf)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 3 folds for each of 324 candidates, totalling 972 fits
Random Forest Test MSE: 3815896212.7555285
Random Forest Test R2: 0.865534268688408</code></pre>
</div>
</div>
</section>
<section id="advanced-regression-analysis" class="level2">
<h2 class="anchored" data-anchor-id="advanced-regression-analysis">Advanced Regression Analysis</h2>
<p><strong>1. Exploring Feature Interactions</strong></p>
<p>Feature interactions can reveal complex relationships that might not be captured by individual features alone.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding interaction terms</span></span>
<span id="cb7-2">poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PolynomialFeatures(degree<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, interaction_only<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, include_bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb7-3">X_train_poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> poly.fit_transform(X_train_prep)</span>
<span id="cb7-4">X_test_poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> poly.transform(X_test_prep)</span>
<span id="cb7-5"></span>
<span id="cb7-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Re-training Linear Regression with Interaction Terms</span></span>
<span id="cb7-7">linear_model_interact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb7-8">linear_model_interact.fit(X_train_poly, y_train)</span>
<span id="cb7-9"></span>
<span id="cb7-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluating the model with interaction terms</span></span>
<span id="cb7-11">y_pred_interact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linear_model_interact.predict(X_test_poly)</span>
<span id="cb7-12">mse_interact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_interact)</span>
<span id="cb7-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MSE with Interaction Terms:"</span>, mse_interact)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE with Interaction Terms: 2983950454.9349637</code></pre>
</div>
</div>
<p><strong>2. Model Diagnostics for Linear Regression</strong></p>
<p>Checking assumptions and diagnostics of linear regression to ensure the validity of the model.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Model Diagnostics</span></span>
<span id="cb9-2">X_train_sm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.add_constant(X_train_prep)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding a constant</span></span>
<span id="cb9-3">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.OLS(y_train, X_train_sm).fit()</span>
<span id="cb9-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(model.summary())</span>
<span id="cb9-5"></span>
<span id="cb9-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Residuals plot</span></span>
<span id="cb9-7">plt.scatter(model.predict(X_train_sm), model.resid)</span>
<span id="cb9-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb9-9">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Residuals'</span>)</span>
<span id="cb9-10">plt.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>)</span>
<span id="cb9-11">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Residuals vs Predicted'</span>)</span>
<span id="cb9-12">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  Price   R-squared:                       0.917
Model:                            OLS   Adj. R-squared:                  0.914
Method:                 Least Squares   F-statistic:                     283.3
Date:                Tue, 09 Jan 2024   Prob (F-statistic):          3.91e-119
Time:                        04:02:04   Log-Likelihood:                -2932.4
No. Observations:                 240   AIC:                             5885.
Df Residuals:                     230   BIC:                             5920.
Df Model:                           9                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const       4.798e+05   2602.372    184.377      0.000    4.75e+05    4.85e+05
x1           1.56e+05   3262.250     47.819      0.000     1.5e+05    1.62e+05
x2          5.035e+04   3267.184     15.410      0.000    4.39e+04    5.68e+04
x3          2.194e+04   3304.761      6.640      0.000    1.54e+04    2.85e+04
x4         -1.011e+04   3260.647     -3.100      0.002   -1.65e+04   -3684.133
x5         -2624.2257   3281.530     -0.800      0.425   -9089.930    3841.478
x6           -41.7240   3263.210     -0.013      0.990   -6471.330    6387.882
x7          1.215e+05   5467.126     22.218      0.000    1.11e+05    1.32e+05
x8           1.26e+05   5609.374     22.456      0.000    1.15e+05    1.37e+05
x9          1.184e+05   6164.082     19.216      0.000    1.06e+05    1.31e+05
x10         1.139e+05   5567.918     20.463      0.000    1.03e+05    1.25e+05
==============================================================================
Omnibus:                        0.912   Durbin-Watson:                   2.215
Prob(Omnibus):                  0.634   Jarque-Bera (JB):                0.697
Skew:                          -0.123   Prob(JB):                        0.706
Kurtosis:                       3.097   Cond. No.                     6.20e+15
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The smallest eigenvalue is 7.83e-30. This might indicate that there are
strong multicollinearity problems or that the design matrix is singular.</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index_files/figure-html/cell-7-output-2.png" width="629" height="449"></p>
</div>
</div>
<p><strong>3. Learning Curves</strong></p>
<p>Understanding how model performance changes as the training set size increases.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Learning curve function</span></span>
<span id="cb11-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot_learning_curve(estimator, X, y, title):</span>
<span id="cb11-3">    train_sizes, train_scores, test_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> learning_curve(estimator, X, y, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, n_jobs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, train_sizes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.linspace(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb11-4">    train_scores_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(train_scores, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb11-5">    test_scores_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(test_scores, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb11-6"></span>
<span id="cb11-7">    plt.figure()</span>
<span id="cb11-8">    plt.title(title)</span>
<span id="cb11-9">    plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Training examples"</span>)</span>
<span id="cb11-10">    plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Score"</span>)</span>
<span id="cb11-11">    plt.plot(train_sizes, train_scores_mean, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o-'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"r"</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Training score"</span>)</span>
<span id="cb11-12">    plt.plot(train_sizes, test_scores_mean, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o-'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"g"</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cross-validation score"</span>)</span>
<span id="cb11-13">    plt.legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"best"</span>)</span>
<span id="cb11-14">    plt.grid()</span>
<span id="cb11-15">    plt.show()</span>
<span id="cb11-16"></span>
<span id="cb11-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plotting learning curve for Linear Regression</span></span>
<span id="cb11-18">plot_learning_curve(linear_model, X_train_prep, y_train, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Linear Regression Learning Curve"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index_files/figure-html/cell-8-output-1.png" width="617" height="449"></p>
</div>
</div>
<p><strong>4. Ensemble Methods</strong></p>
<p>Combining multiple regression models to improve predictive performance.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gradient Boosting Regressor</span></span>
<span id="cb12-2">gb_reg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GradientBoostingRegressor(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb12-3">gb_reg.fit(X_train_prep, y_train)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluation</span></span>
<span id="cb12-6">y_pred_gb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gb_reg.predict(X_test_prep)</span>
<span id="cb12-7">mse_gb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_gb)</span>
<span id="cb12-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gradient Boosting Regressor MSE:"</span>, mse_gb)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Gradient Boosting Regressor MSE: 3673304675.984175</code></pre>
</div>
</div>
</section>
<section id="deeper-regression-analysis" class="level2">
<h2 class="anchored" data-anchor-id="deeper-regression-analysis">Deeper Regression Analysis</h2>
<p><strong>Feature Importance-Based Selection</strong></p>
<p>First, let’s use a model to identify the most important features and then retrain our models using only these features.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feature Importance with Random Forest</span></span>
<span id="cb14-2">rf_for_importance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestRegressor()</span>
<span id="cb14-3">rf_for_importance.fit(X_train_prep, y_train)</span>
<span id="cb14-4"></span>
<span id="cb14-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get feature importances and corresponding feature names</span></span>
<span id="cb14-6">importances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rf_for_importance.feature_importances_</span>
<span id="cb14-7">feature_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prep_pipeline.get_feature_names_out()</span>
<span id="cb14-8"></span>
<span id="cb14-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a DataFrame for visualization</span></span>
<span id="cb14-10">importance_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature'</span>: feature_names, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Importance'</span>: importances}).sort_values(by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Importance'</span>, ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb14-11"></span>
<span id="cb14-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjusting the threshold for feature selection</span></span>
<span id="cb14-13">top_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> importance_df[importance_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Importance'</span>].cumsum() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.90</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature'</span>]</span>
<span id="cb14-14"></span>
<span id="cb14-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure that top_features is not empty</span></span>
<span id="cb14-16"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(top_features) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb14-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"No features selected. Consider loosening the feature selection criterion."</span>)</span>
<span id="cb14-18"></span>
<span id="cb14-19">X_train_top <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_prep[:, [feature_names.tolist().index(feat) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> feat <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> top_features]]</span>
<span id="cb14-20">X_test_top <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_test_prep[:, [feature_names.tolist().index(feat) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> feat <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> top_features]]</span>
<span id="cb14-21"></span>
<span id="cb14-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Re-train models with top features</span></span>
<span id="cb14-23">linear_model_top <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb14-24">linear_model_top.fit(X_train_top, y_train)</span>
<span id="cb14-25"></span>
<span id="cb14-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluation</span></span>
<span id="cb14-27">y_pred_top <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linear_model_top.predict(X_test_top)</span>
<span id="cb14-28">mse_top <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_top)</span>
<span id="cb14-29"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Top Features Linear Regression MSE:"</span>, mse_top)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top Features Linear Regression MSE: 5967275811.385474</code></pre>
</div>
</div>
</section>
<section id="advanced-non-linear-models" class="level2">
<h2 class="anchored" data-anchor-id="advanced-non-linear-models">Advanced Non-Linear Models</h2>
<p>Incorporating more complex non-linear models such as Support Vector Regression and Neural Networks.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Support Vector Regression</span></span>
<span id="cb16-2">svr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SVR(kernel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rbf'</span>, C<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, gamma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scale'</span>)</span>
<span id="cb16-3">svr.fit(X_train_prep, y_train)</span>
<span id="cb16-4"></span>
<span id="cb16-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluation</span></span>
<span id="cb16-6">y_pred_svr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svr.predict(X_test_prep)</span>
<span id="cb16-7">mse_svr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_svr)</span>
<span id="cb16-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Support Vector Regression MSE:"</span>, mse_svr)</span>
<span id="cb16-9"></span>
<span id="cb16-10">nn_reg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MLPRegressor(hidden_layer_sizes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>), </span>
<span id="cb16-11">                      max_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5000</span>, </span>
<span id="cb16-12">                      learning_rate_init<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>, </span>
<span id="cb16-13">                      solver<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'adam'</span>, </span>
<span id="cb16-14">                      early_stopping<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, </span>
<span id="cb16-15">                      n_iter_no_change<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb16-16">                      random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb16-17">nn_reg.fit(X_train_prep, y_train)</span>
<span id="cb16-18"></span>
<span id="cb16-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluation</span></span>
<span id="cb16-20">y_pred_nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn_reg.predict(X_test_prep)</span>
<span id="cb16-21">mse_nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_nn)</span>
<span id="cb16-22"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Neural Network Regression MSE:"</span>, mse_nn)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Support Vector Regression MSE: 28406556463.671677
Neural Network Regression MSE: 397201687873.44415</code></pre>
</div>
</div>
<p><strong>Building and Evaluating the Linear Regression Model</strong></p>
<p><strong>A. Final Model Training</strong></p>
<p>We’ll train the final models using the best parameters found from previous steps.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb18-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.neural_network <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MLPRegressor</span>
<span id="cb18-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error, r2_score</span>
<span id="cb18-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb18-5"></span>
<span id="cb18-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Linear Regression</span></span>
<span id="cb18-7">linear_model_final <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb18-8">linear_model_final.fit(X_train_prep, y_train)</span>
<span id="cb18-9"></span>
<span id="cb18-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Neural Network</span></span>
<span id="cb18-11">nn_model_final <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MLPRegressor(hidden_layer_sizes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>), </span>
<span id="cb18-12">                              max_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5000</span>, </span>
<span id="cb18-13">                              learning_rate_init<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>, </span>
<span id="cb18-14">                              solver<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'adam'</span>, </span>
<span id="cb18-15">                              early_stopping<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, </span>
<span id="cb18-16">                              n_iter_no_change<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb18-17">                              random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb18-18">nn_model_final.fit(X_train_prep, y_train)</span>
<span id="cb18-19"></span>
<span id="cb18-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predictions</span></span>
<span id="cb18-21">y_pred_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linear_model_final.predict(X_test_prep)</span>
<span id="cb18-22">y_pred_nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn_model_final.predict(X_test_prep)</span></code></pre></div>
</div>
<p><strong>B. Evaluation Metrics</strong></p>
<p>Calculating and printing evaluation metrics for both models. We’ll train the final models using the best parameters found from previous steps.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluation for Linear Regression</span></span>
<span id="cb19-2">mse_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_linear)</span>
<span id="cb19-3">r2_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> r2_score(y_test, y_pred_linear)</span>
<span id="cb19-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Linear Regression - MSE:"</span>, mse_linear, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R2:"</span>, r2_linear)</span>
<span id="cb19-5"></span>
<span id="cb19-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluation for Neural Network</span></span>
<span id="cb19-7">mse_nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_nn)</span>
<span id="cb19-8">r2_nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> r2_score(y_test, y_pred_nn)</span>
<span id="cb19-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Neural Network - MSE:"</span>, mse_nn, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R2:"</span>, r2_nn)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression - MSE: 2520672652.9396286 R2: 0.9111757572070075
Neural Network - MSE: 397201687873.44415 R2: -12.996715964015438</code></pre>
</div>
</div>
<p><strong>C. Plotting Model Performance</strong></p>
<p>Visualizing the performance of the models using scatter plots and residual plots.</p>
<p><strong>I. Scatter Plot for Predictions.</strong></p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb21-2"></span>
<span id="cb21-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Scatter plot for Linear Regression</span></span>
<span id="cb21-4">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb21-5">plt.scatter(y_test, y_pred_linear, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb21-6">plt.plot([y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], [y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k--'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb21-7">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual'</span>)</span>
<span id="cb21-8">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb21-9">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Linear Regression Predictions'</span>)</span>
<span id="cb21-10"></span>
<span id="cb21-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Scatter plot for Neural Network</span></span>
<span id="cb21-12">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb21-13">plt.scatter(y_test, y_pred_nn, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>)</span>
<span id="cb21-14">plt.plot([y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], [y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k--'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb21-15">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual'</span>)</span>
<span id="cb21-16">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb21-17">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neural Network Predictions'</span>)</span>
<span id="cb21-18"></span>
<span id="cb21-19">plt.tight_layout()</span>
<span id="cb21-20">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index_files/figure-html/cell-14-output-1.png" width="1142" height="566"></p>
</div>
</div>
<p><strong>II. Residual Plot</strong></p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb22-2"></span>
<span id="cb22-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Residual plot for Linear Regression</span></span>
<span id="cb22-4">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb22-5">plt.scatter(y_pred_linear, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_pred_linear, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb22-6">plt.hlines(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, xmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_linear.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), xmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_linear.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(), colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dashed'</span>)</span>
<span id="cb22-7">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb22-8">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Residuals'</span>)</span>
<span id="cb22-9">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Linear Regression Residuals'</span>)</span>
<span id="cb22-10"></span>
<span id="cb22-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Residual plot for Neural Network</span></span>
<span id="cb22-12">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb22-13">plt.scatter(y_pred_nn, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_pred_nn, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>)</span>
<span id="cb22-14">plt.hlines(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, xmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_nn.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), xmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_nn.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(), colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dashed'</span>)</span>
<span id="cb22-15">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb22-16">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Residuals'</span>)</span>
<span id="cb22-17">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neural Network Residuals'</span>)</span>
<span id="cb22-18"></span>
<span id="cb22-19">plt.tight_layout()</span>
<span id="cb22-20">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index_files/figure-html/cell-15-output-1.png" width="1142" height="566"></p>
</div>
</div>
<p><strong>Building and Evaluating Non-Linear Model (Support Vector Regression)</strong></p>
<p><strong>A. Training the Support Vector Regressor</strong></p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.svm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SVR</span>
<span id="cb23-2"></span>
<span id="cb23-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Support Vector Regression</span></span>
<span id="cb23-4">svr_model_final <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SVR(kernel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rbf'</span>, C<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, gamma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scale'</span>)</span>
<span id="cb23-5">svr_model_final.fit(X_train_prep, y_train)</span>
<span id="cb23-6"></span>
<span id="cb23-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predictions</span></span>
<span id="cb23-8">y_pred_svr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svr_model_final.predict(X_test_prep)</span></code></pre></div>
</div>
<p><strong>B. Evaluation Metrics for SVR</strong></p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluation for Support Vector Regression</span></span>
<span id="cb24-2">mse_svr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_svr)</span>
<span id="cb24-3">r2_svr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> r2_score(y_test, y_pred_svr)</span>
<span id="cb24-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Support Vector Regression - MSE:"</span>, mse_svr, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R2:"</span>, r2_svr)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Support Vector Regression - MSE: 28406556463.671677 R2: -0.0009990251211158263</code></pre>
</div>
</div>
<p><strong>C. Plotting Comparisons</strong></p>
<p>Visualizing the performance of the Linear Regression, Neural Network, and Support Vector Regression models.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb26-2"></span>
<span id="cb26-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Linear Regression</span></span>
<span id="cb26-4">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb26-5">plt.scatter(y_test, y_pred_linear, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb26-6">plt.plot([y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], [y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k--'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb26-7">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual'</span>)</span>
<span id="cb26-8">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb26-9">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Linear Regression Predictions'</span>)</span>
<span id="cb26-10"></span>
<span id="cb26-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Neural Network</span></span>
<span id="cb26-12">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb26-13">plt.scatter(y_test, y_pred_nn, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>)</span>
<span id="cb26-14">plt.plot([y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], [y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k--'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb26-15">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual'</span>)</span>
<span id="cb26-16">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb26-17">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neural Network Predictions'</span>)</span>
<span id="cb26-18"></span>
<span id="cb26-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Support Vector Regression</span></span>
<span id="cb26-20">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb26-21">plt.scatter(y_test, y_pred_svr, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>)</span>
<span id="cb26-22">plt.plot([y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], [y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), y_test.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k--'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb26-23">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual'</span>)</span>
<span id="cb26-24">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb26-25">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Support Vector Regression Predictions'</span>)</span>
<span id="cb26-26"></span>
<span id="cb26-27">plt.tight_layout()</span>
<span id="cb26-28">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index_files/figure-html/cell-18-output-1.png" width="1718" height="566"></p>
</div>
</div>
<p><strong>D. Residual Plot for All Models</strong></p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb27-2"></span>
<span id="cb27-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Linear Regression Residuals</span></span>
<span id="cb27-4">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb27-5">plt.scatter(y_pred_linear, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_pred_linear, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb27-6">plt.hlines(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, xmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_linear.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), xmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_linear.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(), colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dashed'</span>)</span>
<span id="cb27-7">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb27-8">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Residuals'</span>)</span>
<span id="cb27-9">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Linear Regression Residuals'</span>)</span>
<span id="cb27-10"></span>
<span id="cb27-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Neural Network Residuals</span></span>
<span id="cb27-12">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb27-13">plt.scatter(y_pred_nn, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_pred_nn, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>)</span>
<span id="cb27-14">plt.hlines(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, xmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_nn.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), xmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_nn.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(), colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dashed'</span>)</span>
<span id="cb27-15">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb27-16">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Residuals'</span>)</span>
<span id="cb27-17">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neural Network Residuals'</span>)</span>
<span id="cb27-18"></span>
<span id="cb27-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SVR Residuals</span></span>
<span id="cb27-20">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb27-21">plt.scatter(y_pred_svr, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_pred_svr, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>)</span>
<span id="cb27-22">plt.hlines(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, xmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_svr.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), xmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_pred_svr.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(), colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dashed'</span>)</span>
<span id="cb27-23">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb27-24">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Residuals'</span>)</span>
<span id="cb27-25">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Support Vector Regression Residuals'</span>)</span>
<span id="cb27-26"></span>
<span id="cb27-27">plt.tight_layout()</span>
<span id="cb27-28">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index_files/figure-html/cell-19-output-1.png" width="1718" height="566"></p>
</div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In conclusion, the fields of random processes and probability theory, as well as linear and nonlinear regression, are vital components of machine learning when applied to diverse datasets such as weather and housing data. These foundational concepts empower us to model and make predictions in the face of inherent uncertainty, allowing for more accurate forecasts, informed decision-making, and improved insights.</p>
<p>For weather data analysis, random processes and probability theory enable us to understand and quantify the stochastic nature of weather patterns. Leveraging machine learning techniques on this data helps us provide accurate forecasts and anticipate extreme events, benefiting numerous sectors that rely on weather information.</p>
<p>In the case of housing data analysis, linear and nonlinear regression techniques enable us to model complex relationships between housing features and prices. Whether it’s linear relationships for straightforward cases or nonlinear models to capture intricate patterns, these tools empower us to make more informed decisions in real estate, investments, and market analysis.</p>
<p>In both domains, machine learning applied to these fundamental concepts provides us with the means to extract valuable insights and make data-driven decisions, ultimately enhancing our understanding and predictive capabilities, and offering practical solutions that can improve the quality of life and the efficiency of various industries.</p>
<script>
const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
</script>
<style>
div#quarto-sidebar-glass { display: none !important; }
ul.navbar-nav.navbar-nav-scroll { -webkit-flex-direction: row !important; }
/* #quarto-sidebar { padding: 5px; }
#quarto-sidebar > * { padding: 5px; }
div.sidebar-menu-container > * { padding: 5px 5px 5px 5px; }
#quarto-margin-sidebar { padding: 40px; } */
</style>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/index.html</guid>
  <pubDate>Fri, 24 Nov 2023 05:00:00 GMT</pubDate>
  <media:content url="https://nishantbharali.github.io/Blog/posts/Linear and Non Linear Regression/AU5v.gif" medium="image" type="image/gif"/>
</item>
</channel>
</rss>
